#!/bin/bash

# Exit on any error
set -e

# Navigate to project directory
cd ~/chatbot-k8s-v2

# Step 1: Create and activate virtual environment
echo "Creating and activating virtual environment..."
if [ ! -d "venv" ]; then
    python3 -m venv venv
fi
source venv/bin/activate

# Step 2: Install dependencies with compatible pinned versions
echo "Installing dependencies with pinned versions..."
pip install --upgrade pip
cat > requirements.txt << 'EOF'
Flask==3.0.3
spacy==3.8.2
kubernetes==30.1.0
requests==2.32.3
PyJWT==2.9.0
flask-limiter==3.8.0
langchain==0.3.1
langchain-community==0.3.1
langchain-chroma==0.1.4
sentence-transformers==3.2.0
langchain-core==0.3.0
langsmith==0.1.17
fuzzywuzzy==0.18.0
pyspellchecker==0.8.3
langchain-huggingface==0.3.0
torch==2.7.1
EOF
pip install -r requirements.txt
pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cpu

# Step 3: Install SpaCy language model
echo "Installing SpaCy language model..."
python3 -m spacy download en_core_web_sm

# Step 4: Resolve Ollama port conflict (port 11434)
echo "Checking for Ollama port conflict on 11434..."
if lsof -i :11434 > /dev/null; then
    echo "Port 11434 is in use, attempting to free it..."
    kill -9 $(lsof -t -i :11434) || true
fi
echo "Starting Ollama server..."
ollama serve > ~/chatbot-k8s-v2/logs/ollama.log 2>&1 &
OLLAMA_PID=$!
sleep 5  # Initial wait for Ollama to start

# Verify Ollama with retries
echo "Verifying Ollama server..."
for i in {1..3}; do
    if curl -s http://localhost:11434/api/tags > /dev/null; then
        echo "Ollama server is running."
        break
    else
        echo "Attempt $i: Ollama server not yet running, waiting..."
        sleep 5
    fi
    if [ $i -eq 3 ]; then
        echo "Error: Ollama server failed to start after retries. Check ~/chatbot-k8s-v2/logs/ollama.log."
        cat ~/chatbot-k8s-v2/logs/ollama.log
        kill $OLLAMA_PID 2>/dev/null || true
        exit 1
    fi
done

# Verify mistral:instruct model
echo "Verifying Ollama mistral:instruct model..."
if ! ollama list | grep -q "mistral:instruct"; then
    echo "Pulling mistral:instruct model..."
    ollama pull mistral:instruct
fi

# Step 5: Ensure directories exist
echo "Creating necessary directories..."
mkdir -p docs logs app/chroma_db

# Step 6: Reinitialize vector store
echo "Reinitializing vector store..."
cd app
rm -rf chroma_db
python3 -c "from rag import initialize_vector_store; initialize_vector_store()"
cd ..

# Step 7: Check for Flask port conflict (port 5000)
echo "Checking for Flask port conflict on 5000..."
if lsof -i :5000 > /dev/null; then
    echo "Port 5000 is in use, attempting to free it..."
    kill3
    kill -9 $(lsof -t -i :5000) || true
fi

# Step 8: Set JWT secret for security
echo "Setting JWT_SECRET_KEY..."
export JWT_SECRET_KEY="your-secure-key-$(uuidgen)"

# Step 9: Start Flask server in the background
echo "Starting Flask server..."
cd app
python3 server.py > ~/chatbot-k8s-v2/logs/flask.log 2>&1 &
FLASK_PID=$!
sleep 5  # Wait for Flask to start

# Verify Flask with retries
echo "Verifying Flask server..."
for i in {1..3}; do
    if curl -s http://localhost:5000 > /dev/null; then
        echo "Flask server is running."
        break
    else
        echo "Attempt $i: Flask server not yet running, waiting..."
        sleep 5
    fi
    if [ $i -eq 3 ]; then
        echo "Error: Flask server failed to start after retries. Check ~/chatbot-k8s-v2/logs/flask.log."
        cat ~/chatbot-k8s-v2/logs/flask.log
        kill $OLLAMA_PID $FLASK_PID 2>/dev/null || true
        exit 1
    fi
done

# Step 10: Keep script running to monitor servers
echo "Chatbot is running at http://localhost:5000"
echo "Ollama PID: $OLLAMA_PID, Flask PID: $FLASK_PID"
echo "Press Ctrl+C to stop the servers..."
wait $FLASK_PID
